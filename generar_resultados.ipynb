{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 22:48:23.834 INFO    visions.backends: Pandas backend loaded 1.3.5\n",
      "2022-09-19 22:48:23.851 INFO    visions.backends: Numpy backend loaded 1.19.5\n",
      "2022-09-19 22:48:23.853 INFO    visions.backends: Pyspark backend NOT loaded\n",
      "2022-09-19 22:48:23.854 INFO    visions.backends: Python backend loaded\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Creada por Maximiliano Jones\n",
    "\n",
    "# Manejo de datos\n",
    "from ast import parse\n",
    "import pandas as pd\n",
    "\n",
    "# Funcionalidades de la aplicación\n",
    "import streamlit as st\n",
    "import base64\n",
    "import pandas_profiling\n",
    "from streamlit_pandas_profiling import st_profile_report\n",
    "\n",
    "# Manejod del tiempo/fechas\n",
    "import pytz\n",
    "import time\n",
    "\n",
    "# Automated Classification\n",
    "from pycaret import classification as supervised\n",
    "# import pycaret.anomaly as unsupervised\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @st.cache(suppress_st_warning=True)\n",
    "def load_data(path):\n",
    "    '''\n",
    "    ARGS: path to the local .csv file\n",
    "    Load data and search for the Date_Time column to index the dataframe by a datetime value.\n",
    "\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(path, sep=None, engine='python',encoding = 'utf-8-sig',parse_dates= True)\n",
    "\n",
    "    try:\n",
    "        data['Date_Time'] = pd.to_datetime(data['Date_Time'])\n",
    "        # st.sidebar.write('Se encontró una columa \"Date_time\"')\n",
    "        data.set_index(\"Date_Time\", inplace=True)\n",
    "        chile = pytz.timezone(\"Chile/Continental\")\n",
    "        data.index = data.index.tz_localize(pytz.utc).tz_convert(chile)\n",
    "        # st.dataframe(data)\n",
    "        return data\n",
    "    except:\n",
    "        try:\n",
    "            data['Datetime'] = pd.to_datetime(data[\"Date_Time\"])\n",
    "            # st.sidebar.write('Se encontró una columa \"Datetime\"')\n",
    "            data.set_index(\"Datetime\", inplace=True)\n",
    "            chile = pytz.timezone(\"Chile/Continental\")\n",
    "            data.index = data.index.tz_localize(pytz.utc).tz_convert(chile)\n",
    "            # st.dataframe(data)\n",
    "            return data\n",
    "        except:\n",
    "            # st.write(\"Se entró en el tercer except\")\n",
    "            # st.sidebar.write(\"No se encontró columna Date_Time\")\n",
    "            return data\n",
    "\n",
    "# @st.cache(allow_output_mutation=True,suppress_st_warning=True)\n",
    "def entrenar_modelos(df, etiqueta, metrica, ensamble=True, debug=True):\n",
    "\n",
    "    '''\n",
    "    ARGS: dataframe (pd.DataFrame),\n",
    "    etiqueta con nombre de dataframe.column (str),\n",
    "    metrica puede ser ['f1', 'accuracy', 'recall'] (str) y\n",
    "    ensamble[default=True, False] (boolean)\n",
    "    '''\n",
    "\n",
    "    # setup\n",
    "    pycaret_s = supervised.setup(df, target=etiqueta, session_id=123, silent=True, use_gpu=False, profile=False, log_experiment=False, fix_imbalance=True)\n",
    "    # model training and selection\n",
    "    if ensamble:\n",
    "        # with st.snow():\n",
    "        top10 = supervised.compare_models(n_select=10)\n",
    "        top5 = top10[0:4]\n",
    "        # tune top 5 base models\n",
    "        grid_a = supervised.pull()\n",
    "        tuned_top5 = [supervised.tune_model(i, fold=5, optimize='F1', search_library='scikit-optimize') for i in top5]\n",
    "        # grid_b = supervised.pull()\n",
    "        stacker = supervised.stack_models(estimator_list=tuned_top5[1:], meta_model=tuned_top5[0])\n",
    "        # if debug:\n",
    "            # st.write(top10)\n",
    "            # st.write(grid_b)\n",
    "        # else:\n",
    "        #     pass\n",
    "            \n",
    "        #\n",
    "        return (stacker, grid_a, grid_a)\n",
    "    else:\n",
    "        best = supervised.compare_models(sort=metrica, n_select=3)\n",
    "        grid = supervised.pull()\n",
    "        return (best, grid, grid)\n",
    "\n",
    "\n",
    "def deteccion_no_supervisada(df, metrica, etiqueta=None, ensamble=True):\n",
    "    return None\n",
    "\n",
    "def cargar_modelo(df, modelo):\n",
    "    modelo = supervised.load_model('stack inicial')\n",
    "\n",
    "    return (modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de gráficos\n",
    "\n",
    "def generar_distrib(loaded_df, etiqueta):\n",
    "    figura = px.histogram(df,x=etiqueta,y=df[etiqueta],color='Etiqueta',template='plotly_white',\n",
    "                    marginal='box',opacity=0.7,nbins=100,color_discrete_sequence=[colors_green[3],colors_blue[3]],\n",
    "                    barmode='group',histfunc='count')\n",
    "                    \n",
    "    figura.update_layout(\n",
    "        font_family='monospace',\n",
    "        title=dict(text=etiqueta,x=0.53,y=0.95,\n",
    "                font=dict(color=colors_dark[2],size=20)),\n",
    "        xaxis_title_text=etiqueta,\n",
    "        yaxis_title_text='Count',\n",
    "        legend=dict(x=1,y=0.96,bordercolor=colors_dark[4],borderwidth=0,tracegroupgap=5),\n",
    "        bargap=0.3,\n",
    "    )\n",
    "    return figura\n",
    "\n",
    "def generar_graficos(selected_df, etiqueta):\n",
    "\n",
    "\n",
    "    describe=selected_df.describe().T.style.bar(subset=['mean'], color='#E68193')\\\n",
    "            .background_gradient(subset=['std'], cmap='mako_r')\\\n",
    "                .background_gradient(subset=['50%'], cmap='mako')\n",
    "    a2.subheader(\"Descripción estadística de los datos cargados\")\n",
    "    a2.dataframe(describe)\n",
    "    df=pd.DataFrame()\n",
    "    df['etiqueta conjunta'] = selected_df['Etiqueta'].replace([0,1],['normal','anomalía'])\n",
    "    d = pd.DataFrame(df['etiqueta conjunta'].value_counts())\n",
    "\n",
    "    fig = px.pie(d,values='etiqueta conjunta',names=['normal','anomalía'],hole=0.4,opacity=0.6,\n",
    "                color_discrete_sequence=[colors_blue[3],colors_green[3]],\n",
    "                labels={'label':'etiqueta conjunta','etiqueta conjunta':'No. Of Samples'})\n",
    "\n",
    "    fig.add_annotation(text='Los resultados sugieren un set de datos desbalanceados',\n",
    "                    x=1.3,y=0.9,showarrow=False,font_size=18,opacity=0.7,font_family='monospace')\n",
    "    fig.add_annotation(text='Etiquetado <br> Experto',\n",
    "                    x=0.5,y=0.5,showarrow=False,font_size=14,opacity=0.7,font_family='monospace')\n",
    "\n",
    "    fig.update_layout(\n",
    "        font_family='monospace',\n",
    "        title=dict(text='. Cuántos datos corresponden a datos normales?',x=0.47,y=0.98,\n",
    "                font=dict(color=colors_dark[2],size=28)),\n",
    "        legend=dict(x=0.37,y=-0.05,orientation='h',traceorder='reversed'),\n",
    "        hoverlabel=dict(bgcolor='white'))\n",
    "\n",
    "    fig.update_traces(textposition='outside', textinfo='percent+label')\n",
    "    st.subheader('Composición de etiquetas:')\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    st.subheader('Distribuciones de las características:')\n",
    "    selected_df['Etiqueta'].replace([0,1],['normal','anomalía'],inplace=True)\n",
    "    for label in selected_features:\n",
    "        f = generar_distrib(selected_df,label)\n",
    "\n",
    "        st.plotly_chart(f, use_container_width=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = load_data('data\\Horcon_1L_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = f.columns.to_list()\n",
    "selected_df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86fa79ed383fe184617ef307b919478dc4dda95960492624715ae9a041c5cb30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
